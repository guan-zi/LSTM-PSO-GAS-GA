{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14411dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import r2_score  # R2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "952c560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置路径\n",
    "input_path = 'C:\\\\Users\\\\iii\\\\Desktop\\\\LSTM+AQI\\\\数据和测算结果\\\\'\n",
    "output_path = 'C:\\\\Users\\\\iii\\\\Desktop\\\\LSTM+AQI\\\\数据和测算结果\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "321737a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data = pd.read_excel(input_path+'aqi_eemd_out.xlsx', index_col='日期')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d38c7",
   "metadata": {},
   "source": [
    "### 先以IMF1为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c57dfbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMF2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日期</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>-29.022702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>36.411221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IMF2\n",
       "日期                   \n",
       "2014-01-01 -29.022702\n",
       "2014-01-02  36.411221"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_IMF = data[['IMF2']]\n",
    "data_IMF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069c498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9b621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5abc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ba7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef34cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1edc8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6778c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1,)\n",
      "计算初始全局最优\n",
      "6/6 [==============================] - 7s 356ms/step - loss: 6574.8149 - val_loss: 970.2161\n",
      "初始全局最优参数：[2.59000000e+02 1.42770708e-01 9.50000000e+01]\n",
      "6/6 [==============================] - 7s 360ms/step - loss: 6574.1631 - val_loss: 970.2322\n",
      "搜索步数：0\n",
      "个体最优参数：[[2.59000000e+02 1.42770708e-01 9.50000000e+01]]\n",
      "全局最优参数：[2.59000000e+02 1.42770708e-01 9.50000000e+01]\n",
      "6/6 [==============================] - 7s 351ms/step - loss: 6573.8984 - val_loss: 970.1818\n",
      "搜索步数：1\n",
      "个体最优参数：[[2.59000000e+02 1.42770708e-01 9.50000000e+01]]\n",
      "全局最优参数：[2.59000000e+02 1.42770708e-01 9.50000000e+01]\n",
      "计算初始全局最优\n",
      "6/6 [==============================] - ETA: 0s - loss: 6574.6372WARNING:tensorflow:5 out of the last 31 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D2E33EAA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6/6 [==============================] - 7s 362ms/step - loss: 6574.6372 - val_loss: 970.0694\n",
      "初始全局最优参数：[2.59000000e+02 1.42770708e-01 9.50000000e+01]\n",
      "6/6 [==============================] - ETA: 0s - loss: 6575.8540WARNING:tensorflow:6 out of the last 33 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D2CCD99040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6/6 [==============================] - 7s 383ms/step - loss: 6575.8540 - val_loss: 970.3442\n",
      "搜索步数：0\n",
      "个体最优参数：[[2.59000000e+02 1.42770708e-01 9.50000000e+01]]\n",
      "全局最优参数：[2.59000000e+02 1.42770708e-01 9.50000000e+01]\n",
      "6/6 [==============================] - 7s 352ms/step - loss: 6572.8188 - val_loss: 969.6815\n",
      "搜索步数：1\n",
      "个体最优参数：[[2.59000000e+02 1.42770708e-01 9.50000000e+01]]\n",
      "全局最优参数：[2.59000000e+02 1.42770708e-01 9.50000000e+01]\n",
      "Running time:  59.042781352996826\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_120 (LSTM)             (None, 10, 259)           269360    \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 10, 259)           0         \n",
      "                                                                 \n",
      " lstm_121 (LSTM)             (None, 10, 128)           198656    \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_122 (LSTM)             (None, 10, 64)            49408     \n",
      "                                                                 \n",
      " lstm_123 (LSTM)             (None, 16)                5184      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 522,625\n",
      "Trainable params: 522,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "6/6 - 6s - loss: 6574.9385 - 6s/epoch - 962ms/step\n",
      "Epoch 2/2\n",
      "6/6 - 0s - loss: 6509.4795 - 419ms/epoch - 70ms/step\n",
      "r^2 值为：  -0.00015502167122294352\n",
      "25.528683533459038\n",
      "[-5.40821838e+00  2.11242879e+00  1.11308354e+01  2.04098532e+01\n",
      "  2.87123338e+01  3.48011290e+01  3.74390905e+01  3.56695401e+01\n",
      "  2.96576810e+01  1.98491865e+01  6.68972995e+00 -9.21633369e+00\n",
      " -2.62925963e+01 -4.14546637e+01 -5.17258596e+01 -5.59096861e+01\n",
      " -5.32362605e+01 -4.34157356e+01 -2.83548378e+01 -1.05140444e+01\n",
      "  7.64616729e+00  2.36653201e+01  3.54412686e+01  4.23051948e+01\n",
      "  4.39550704e+01  4.04471045e+01  3.31435867e+01  2.37312122e+01\n",
      "  1.37690071e+01  4.30532031e+00 -3.83886318e+00 -1.02413364e+01\n",
      " -1.45795868e+01 -1.65311020e+01 -1.59610333e+01 -1.34898545e+01\n",
      " -9.94437293e+00 -6.07474717e+00 -2.30587003e+00  1.01868210e+00\n",
      "  3.55533281e+00  4.96050569e+00  4.98776857e+00 -2.89180254e+01\n",
      " -2.97677296e+01 -2.91615635e+01 -2.69994069e+01 -2.34479293e+01\n",
      " -1.87402917e+01 -1.31096546e+01 -6.78917890e+00 -1.20252797e-02\n",
      "  6.98864549e+00  1.39696407e+01  2.06418109e+01  2.66826586e+01\n",
      "  3.17638573e+01  3.55570803e+01  3.77340011e+01  3.79662932e+01\n",
      "  3.60293669e+01  3.21135794e+01  2.65130250e+01  1.95217978e+01\n",
      "  1.14339920e+01  2.54370184e+00 -6.85497865e+00 -1.64491633e+01\n",
      " -2.58507980e+01 -3.46449457e+01 -4.23843037e+01 -4.86134783e+01\n",
      " -5.29367609e+01 -5.52378740e+01 -5.56228579e+01 -5.42374630e+01\n",
      " -5.12254770e+01 -4.67302299e+01 -4.09017529e+01 -3.39168819e+01\n",
      " -2.59591543e+01 -1.72121072e+01 -7.86504267e+00  1.86623099e+00\n",
      "  1.17463499e+01  2.15365026e+01  3.09978774e+01  3.98916629e+01\n",
      "  4.79790475e+01  5.50212197e+01  6.07793678e+01  6.50146804e+01\n",
      "  6.74883459e+01  6.79615528e+01  6.62453233e+01  6.23896958e+01\n",
      "  5.66532680e+01  4.93343190e+01  4.07311277e+01  3.11419733e+01\n",
      "  2.08651346e+01  1.01988908e+01 -5.58479085e-01 -1.11086961e+01\n",
      " -2.11583049e+01 -3.04352360e+01 -3.86770086e+01 -4.56088324e+01\n",
      " -5.09523172e+01 -5.44763429e+01 -5.61388703e+01 -5.59824151e+01\n",
      " -5.41985944e+01 -5.10161602e+01 -4.66638267e+01 -4.13703080e+01\n",
      " -3.53664081e+01 -2.88912889e+01 -2.21681706e+01 -1.53481465e+01\n",
      " -8.56427862e+00 -1.94962889e+00  4.36274081e+00  1.02397686e+01\n",
      "  1.55483924e+01  2.01555506e+01  2.39281810e+01  2.67720768e+01\n",
      "  2.87484510e+01  2.99583842e+01  3.05070081e+01  3.05009300e+01\n",
      "  3.00486098e+01  2.92589701e+01  2.82409339e+01  2.71034239e+01\n",
      "  2.59369341e+01  2.47582428e+01  2.35656996e+01  2.23576539e+01\n",
      "  2.11324554e+01  1.98884535e+01  1.86239978e+01  1.73374377e+01\n",
      "  1.60186649e+01  1.46334183e+01  1.31776957e+01  1.16571737e+01\n",
      "  1.00775292e+01  8.44443886e+00  6.76357953e+00  5.04062795e+00\n",
      "  3.28126089e+00  1.49115510e+00 -3.18253086e-01 -2.10782172e+00\n",
      " -3.81397936e+00 -5.36848708e+00 -6.70310596e+00 -7.74959706e+00\n",
      " -8.43972147e+00 -8.70524026e+00 -8.49633941e+00]\n",
      "[2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618197 2.3618197 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618197\n",
      " 2.3618197 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618197 2.3618197 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618197 2.3618197 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618197 2.3618197 2.3618197\n",
      " 2.3618197 2.3618197]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DataScience\\Anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 31532 (\\N{CJK UNIFIED IDEOGRAPH-7B2C}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\DataScience\\Anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\DataScience\\Anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 36845 (\\N{CJK UNIFIED IDEOGRAPH-8FED}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "D:\\DataScience\\Anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 20195 (\\N{CJK UNIFIED IDEOGRAPH-4EE3}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 2\n",
    "# steps = 10\n",
    "\n",
    "def process_data():\n",
    "    dataset = data_IMF\n",
    "    #columns = ['SP', 'High', 'Low', 'KP', 'QSP', 'ZDE', 'ZDF', 'CJL']\n",
    "    columns = ['IMF2']\n",
    "    '''\n",
    "    for col in columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        dataset[col] = scaler.fit_transform(dataset[col].values.reshape(-1, 1))\n",
    "    '''\n",
    "    X = dataset.drop(columns=['IMF2'], axis=1)\n",
    "    y = dataset['IMF2']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, shuffle=False, random_state=666)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def create_dataset(X, y, seq_len=10):\n",
    "    features = []\n",
    "    targets = []  # 标签\n",
    "\n",
    "    for i in range(0, len(X) - seq_len, 1):  # 此处的1表示步长，每隔一步滑一下\n",
    "        data = X.iloc[i:i + seq_len]  # 序列数据；前闭后开\n",
    "        label = y.iloc[i + seq_len]  # 标签数据\n",
    "        # 保存到features和labels\n",
    "        features.append(data)\n",
    "        targets.append(label)\n",
    "\n",
    "    return np.array(features), np.array(targets)\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = process_data()\n",
    "train_dataset, train_labels = create_dataset(X_train, y_train, seq_len=10)\n",
    "X_test, y_test = create_dataset(X_test, y_test, seq_len=10)\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "def build_model(neurons, dropout):\n",
    "    model = Sequential([\n",
    "        layers.LSTM(units=neurons, input_shape=train_dataset.shape[-2:], return_sequences=True),\n",
    "        # units=256表示有256个神经元；return_sequences=True表示将结果传到下一步\n",
    "        layers.Dropout(dropout),  # 表示删除一些神经元\n",
    "        layers.LSTM(units=128, return_sequences=True),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.LSTM(units=64, return_sequences=True),\n",
    "        layers.LSTM(units=16),\n",
    "        layers.Dense(1)  # 因为只有一个特征值的输出\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def training(X):\n",
    "    neurons = int(X[0])\n",
    "    dropout = round(X[1], 6)\n",
    "    batch_size = int(X[2])\n",
    "    model = build_model(neurons, dropout)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse')\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=1)\n",
    "    model.save(\n",
    "        'neurons' + str(int(X[0])) + '_dropout' + str(dropout) + '_batch_size' + str(batch_size) + '.h5')\n",
    "    # 训练完成后可直接加载模型\n",
    "    # model_lstm = load_model('LSTM_bus_' + str(X[0]) + '_' + str(X[1]) + '_' + str(X[2]) + '_' + '.h5')\n",
    "    pred = model.predict(X_test)\n",
    "    le = len(pred)\n",
    "    y_t = y_test.reshape(-1, 1)\n",
    "    return pred, le, y_t\n",
    "\n",
    "\n",
    "def function(ps, test, le):\n",
    "    ss = sum(((abs(test - ps)) / test) / le)\n",
    "    return ss\n",
    "\n",
    "\n",
    "# (1) PSO Parameters\n",
    "MAX_EPISODES = 2\n",
    "MAX_EP_STEPS = 2\n",
    "c1 = 1\n",
    "c2 = 1\n",
    "w = 0.5\n",
    "pN = 1  # 粒子数量\n",
    "\n",
    "# (2) LSTM Parameters\n",
    "dim = 3  # 搜索维度\n",
    "X = np.zeros((pN, dim))  # 所有粒子的位置和速度\n",
    "V = np.zeros((pN, dim))\n",
    "pbest = np.zeros((pN, dim))  # 个体经历的最佳位置和全局最佳位置\n",
    "gbest = np.zeros(dim)\n",
    "p_fit = np.zeros(pN)  # 每个个体的历史最佳适应值\n",
    "print(p_fit.shape)\n",
    "print(p_fit.shape)\n",
    "t1 = time.time()\n",
    "\n",
    "'''\n",
    "神经网络第一层神经元个数： 256-259\n",
    "dropout比率： 0.03-0.19\n",
    "batch_size： 64-128\n",
    "'''\n",
    "UP = [259, 0.19, 128]\n",
    "DOWN = [256, 0.03, 64]\n",
    "\n",
    "# (4) 开始搜索\n",
    "for i_episode in range(MAX_EPISODES):\n",
    "    \"\"\"初始化s\"\"\"\n",
    "    random.seed(8)\n",
    "    fit = -1e5  # 全局最佳适应值\n",
    "    # 初始粒子适应度计算\n",
    "    print(\"计算初始全局最优\")\n",
    "    for i in range(pN):\n",
    "        for j in range(dim):\n",
    "            V[i][j] = random.uniform(0, 1)\n",
    "            if j == 1:\n",
    "                X[i][j] = random.uniform(DOWN[j], UP[j])\n",
    "            else:\n",
    "                X[i][j] = round(random.randint(DOWN[j], UP[j]), 0)\n",
    "        pbest[i] = X[i]\n",
    "        le, pred, y_t = training(X[i])\n",
    "        NN = 1\n",
    "        tmp = function(pred, y_t, le)\n",
    "        p_fit[i] = tmp\n",
    "        if tmp > fit:\n",
    "            fit = tmp\n",
    "            gbest = X[i]\n",
    "    print(\"初始全局最优参数：{:}\".format(gbest))\n",
    "\n",
    "    fitness = []  # 适应度函数\n",
    "    for j in range(MAX_EP_STEPS):\n",
    "        fit2 = []\n",
    "        plt.title(\"第{}次迭代\".format(i_episode))\n",
    "        for i in range(pN):\n",
    "            le, pred, y_t = training(X[i])\n",
    "            temp = function(pred, y_t, le)\n",
    "            fit2.append(temp / 1000)\n",
    "            if temp > p_fit[i]:  # 更新个体最优\n",
    "                p_fit[i] = temp\n",
    "                pbest[i] = X[i]\n",
    "                if p_fit[i] > fit:  # 更新全局最优\n",
    "                    gbest = X[i]\n",
    "                    fit = p_fit[i]\n",
    "        print(\"搜索步数：{:}\".format(j))\n",
    "        print(\"个体最优参数：{:}\".format(pbest))\n",
    "        print(\"全局最优参数：{:}\".format(gbest))\n",
    "        # [30.          0.14277071 95.        ]\n",
    "        for i in range(pN):\n",
    "            V[i] = w * V[i] + c1 * random.uniform(0, 1) * (pbest[i] - X[i]) + c2 * random.uniform(0, 1) * (gbest - X[i])\n",
    "            ww = 1\n",
    "            for k in range(dim):\n",
    "                if DOWN[k] < X[i][k] + V[i][k] < UP[k]:\n",
    "                    continue\n",
    "                else:\n",
    "                    ww = 0\n",
    "            X[i] = X[i] + V[i] * ww\n",
    "        fitness.append(fit)\n",
    "\n",
    "print('Running time: ', time.time() - t1)\n",
    "\n",
    "# 训练模型  使用PSO找到的最好的神经元个数\n",
    "neurons = int(gbest[0])\n",
    "dropout = gbest[1]\n",
    "batch_size = int(gbest[2])\n",
    "model = build_model(neurons, dropout)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse')\n",
    "model.summary()\n",
    "history = model.fit(train_dataset, train_labels, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "# 模型预测数据\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds = test_preds[:, 0] # 获取数组中的第1列值\n",
    "\n",
    "\n",
    "# 计算r2值\n",
    "score = r2_score(y_test, test_preds)\n",
    "print(\"r^2 值为： \", score)\n",
    "'''\n",
    "# 绘制 预测与真值结果\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_test[:1149], label=\"True value\")\n",
    "plt.plot(test_preds[:1149], label=\"Pred value\")#预测值\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# 显示训练结果\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "'''\n",
    "from sklearn import metrics\n",
    "'''\n",
    "#MSE\n",
    "print(metrics.mean_squared_error(y_test,test_preds))\n",
    "#RMSE\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test,test_preds)))\n",
    "'''\n",
    "#MAE\n",
    "print(metrics.mean_absolute_error(y_test,test_preds))\n",
    "print(y_test)\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec3f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e226079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.40821838e+00  2.11242879e+00  1.11308354e+01  2.04098532e+01\n",
      "  2.87123338e+01  3.48011290e+01  3.74390905e+01  3.56695401e+01\n",
      "  2.96576810e+01  1.98491865e+01  6.68972995e+00 -9.21633369e+00\n",
      " -2.62925963e+01 -4.14546637e+01 -5.17258596e+01 -5.59096861e+01\n",
      " -5.32362605e+01 -4.34157356e+01 -2.83548378e+01 -1.05140444e+01\n",
      "  7.64616729e+00  2.36653201e+01  3.54412686e+01  4.23051948e+01\n",
      "  4.39550704e+01  4.04471045e+01  3.31435867e+01  2.37312122e+01\n",
      "  1.37690071e+01  4.30532031e+00 -3.83886318e+00 -1.02413364e+01\n",
      " -1.45795868e+01 -1.65311020e+01 -1.59610333e+01 -1.34898545e+01\n",
      " -9.94437293e+00 -6.07474717e+00 -2.30587003e+00  1.01868210e+00\n",
      "  3.55533281e+00  4.96050569e+00  4.98776857e+00 -2.89180254e+01\n",
      " -2.97677296e+01 -2.91615635e+01 -2.69994069e+01 -2.34479293e+01\n",
      " -1.87402917e+01 -1.31096546e+01 -6.78917890e+00 -1.20252797e-02\n",
      "  6.98864549e+00  1.39696407e+01  2.06418109e+01  2.66826586e+01\n",
      "  3.17638573e+01  3.55570803e+01  3.77340011e+01  3.79662932e+01\n",
      "  3.60293669e+01  3.21135794e+01  2.65130250e+01  1.95217978e+01\n",
      "  1.14339920e+01  2.54370184e+00 -6.85497865e+00 -1.64491633e+01\n",
      " -2.58507980e+01 -3.46449457e+01 -4.23843037e+01 -4.86134783e+01\n",
      " -5.29367609e+01 -5.52378740e+01 -5.56228579e+01 -5.42374630e+01\n",
      " -5.12254770e+01 -4.67302299e+01 -4.09017529e+01 -3.39168819e+01\n",
      " -2.59591543e+01 -1.72121072e+01 -7.86504267e+00  1.86623099e+00\n",
      "  1.17463499e+01  2.15365026e+01  3.09978774e+01  3.98916629e+01\n",
      "  4.79790475e+01  5.50212197e+01  6.07793678e+01  6.50146804e+01\n",
      "  6.74883459e+01  6.79615528e+01  6.62453233e+01  6.23896958e+01\n",
      "  5.66532680e+01  4.93343190e+01  4.07311277e+01  3.11419733e+01\n",
      "  2.08651346e+01  1.01988908e+01 -5.58479085e-01 -1.11086961e+01\n",
      " -2.11583049e+01 -3.04352360e+01 -3.86770086e+01 -4.56088324e+01\n",
      " -5.09523172e+01 -5.44763429e+01 -5.61388703e+01 -5.59824151e+01\n",
      " -5.41985944e+01 -5.10161602e+01 -4.66638267e+01 -4.13703080e+01\n",
      " -3.53664081e+01 -2.88912889e+01 -2.21681706e+01 -1.53481465e+01\n",
      " -8.56427862e+00 -1.94962889e+00  4.36274081e+00  1.02397686e+01\n",
      "  1.55483924e+01  2.01555506e+01  2.39281810e+01  2.67720768e+01\n",
      "  2.87484510e+01  2.99583842e+01  3.05070081e+01  3.05009300e+01\n",
      "  3.00486098e+01  2.92589701e+01  2.82409339e+01  2.71034239e+01\n",
      "  2.59369341e+01  2.47582428e+01  2.35656996e+01  2.23576539e+01\n",
      "  2.11324554e+01  1.98884535e+01  1.86239978e+01  1.73374377e+01\n",
      "  1.60186649e+01  1.46334183e+01  1.31776957e+01  1.16571737e+01\n",
      "  1.00775292e+01  8.44443886e+00  6.76357953e+00  5.04062795e+00\n",
      "  3.28126089e+00  1.49115510e+00 -3.18253086e-01 -2.10782172e+00\n",
      " -3.81397936e+00 -5.36848708e+00 -6.70310596e+00 -7.74959706e+00\n",
      " -8.43972147e+00 -8.70524026e+00 -8.49633941e+00]\n",
      "[2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618197 2.3618197 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618197\n",
      " 2.3618197 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618197 2.3618197 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618197 2.3618197 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195 2.3618195\n",
      " 2.3618195 2.3618195 2.3618195 2.3618195 2.3618197 2.3618197 2.3618197\n",
      " 2.3618197 2.3618197]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbaca4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c784a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
